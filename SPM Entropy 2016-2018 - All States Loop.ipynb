{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PURPOSE: This code will import SPM estimates (compiled using STATA from the CPS-ASEC and the ACS), run a",
    "#maximum entropy model to estimate the error of PUMA-level SPM rates, and export the results for each state.",
    "#The maximum entropy model will use the state-level SPM rates from the (relatively) more reliable CPS-ASEC to",
    "#constrain the PUMA-level SPM rates from the ACS.",
    "",
    "#ATTRIBUTIONS: Help with the structure of the code was provided by Elissa Cohen.", 
    "", 
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define any functions that will be used later in the code. \n",
    "def column(matrix, i):\n",
    "    return [row[i] for row in matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data: \n",
    "data = pd.read_excel(r\"C:\\Users\\Danielle Wilson\\Dropbox\\SPM_ASEC_ACS_project\\acs_cps_pooled_spm_2016_18.xlsx\", header=0)\n",
    "\n",
    "# Create list of unique gestfips values:\n",
    "unique_gf_set = set(data['state_gestfips']) # Values in set \n",
    "gestfips = list(unique_gf_set) # Turn set into list \n",
    "\n",
    "\n",
    "## BEGIN LOOP OVER STATES **********************************************\n",
    "for s in gestfips: \n",
    "    \n",
    "    #Only keep one state: \n",
    "    # Data observations only begin at the first cell (0) for AL. Otherwise, they start at whatever row number the first  \n",
    "    # state record is listed in the XLSX doc. For example, if you keep data with only \"state_gestfups == 2\", the first line \n",
    "    # observation will be record (i.e. cell) 34, not zero. \n",
    "\n",
    "    data2= data[data.state_gestfips == s] \n",
    "    #print(data2)\n",
    "\n",
    "    # \"Grab\" indicies from imported data. \n",
    "    index_list = data2.index.tolist()\n",
    "    # Store the value of the first index \n",
    "    first_index = index_list[0]\n",
    "    \n",
    "    # \"Grab\" and prepare data for entropy maximization problem. Data will be saved/stored as numbers or vectors. \n",
    "    ##Pumas:\n",
    "    puma = data2['puma']\n",
    "    num_pumas = len(puma) #Number of PUMAs in state. \n",
    "        #print(num_pumas)\n",
    "\n",
    "    #CPS data: \n",
    "    ##CPS State SPM Rate (Number): \n",
    "    r_s_cps = data2['cps_w_spmu_poor_ms'] \n",
    "    r_s_cps_num = r_s_cps[first_index] #Only need the first element because this value will be the same for all PUMAs. \n",
    "        #print(r_s_cps_num)  \n",
    "\n",
    "    #ACS data: \n",
    "    ##ACS PUMA SPM Rate (List):\n",
    "    r_sp_acs = data2['w_spmu_poor_ms_p'] #Saves as smaller dataframe. \n",
    "    ###Transfrom rate into vector (rather than dataframe). \n",
    "    nr_sp_acs = np.matrix(np.reshape(r_sp_acs.to_numpy(), (num_pumas,1)))\n",
    "\n",
    "    ##ACS PUMA Weighted Population Size (List):\n",
    "    n_sp_acs = data2['w_count_Ns_p']\n",
    "    ###Transfrom population size into vector (rather than dataframe).\n",
    "    nn_sp_acs = np.matrix(np.reshape(n_sp_acs.to_numpy(), (num_pumas,1)))\n",
    "\n",
    "    ##ACS State Weighted Population Size (Number): \n",
    "    n_s_acs = data2['w_count_Ns']\n",
    "    n_s_acs_num = n_s_acs[first_index]\n",
    "    \n",
    "    # Create Support Space Vectors:\n",
    "    # Will create 7 support space vectors: -3se, -2se, -1se, 0 , se, 2se, 3se. \n",
    "    # Can choose to maximize entropy over a 7 or 3 dimensional support space vector. \n",
    "    # Note that support space vectors are PUMA spesific - in other words, each PUMA has thier own support space. \n",
    "\n",
    "    ##Save S.E.\n",
    "    se_p = data2['w_spmu_poor_ses_p']\n",
    "    nse_p = np.matrix(np.reshape(se_p.to_numpy(), (num_pumas,1)))\n",
    "\n",
    "    ##Create vecotrs for each support space element: \n",
    "    #v1_p = np.multiply(nse_p, -3) # (-3 x s.e.)\n",
    "    v1_p = np.multiply(nse_p, -10)  # (-10 x s.e.)\n",
    "    v2_p = np.multiply(nse_p, -2)  # (-2 x s.e.)\n",
    "    v3_p = np.multiply(nse_p, -1)  # (-1 x s.e.)\n",
    "    v4_p = np.multiply(nse_p, 0)   # (0 x s.e.)\n",
    "    v5_p = np.multiply(nse_p, 1)   # (1 x s.e.)\n",
    "    v6_p = np.multiply(nse_p, 2)   # (2 x s.e.)\n",
    "    #v7_p = np.multiply(nse_p, 3)  # (3 x s.e.)\n",
    "    v7_p = np.multiply(nse_p, 10)   # (10 x s.e.)\n",
    "\n",
    "    # Check to make sure that error bounds do not exceed [0,1]. \n",
    "    lower_check = nr_sp_acs + v1_p\n",
    "    upper_check = nr_sp_acs + v7_p\n",
    "        #print(lower_check)\n",
    "        #print(upper_check)\n",
    "    if ((lower_check > 0).sum() == lower_check.size).astype(np.int) != 1:\n",
    "        # sys.exit(\"Error: Lower bound exceeds [0,1]\") \n",
    "        # Differences between ACS and CPS Estimates are so large for some states that the support space defined above\n",
    "        # exceeds the rational bounds. If lower support space bound is less than zero, replace it with zero. \n",
    "        for n, i in enumerate(lower_check):\n",
    "            if i < 0:\n",
    "                lower_check[n] = 0\n",
    "        \n",
    "\n",
    "    if ((upper_check > 1).sum() == upper_check.size).astype(np.int) != 1:\n",
    "        sys.exit(\"Error: Upper bound exceeds [0,1]\")\n",
    "        \n",
    "    #Create Matrix of Unkown Probabilities \n",
    "    #Creating a `num_pumas` by 7/3 matrix (7/3 because there are 7/3 dimensional support spaces for each PUMA). \n",
    "    #The matrix \"w\" will be the matrix associated with the probabilities of the support space outcomes (for each PUMA i.e. row). \n",
    "    #Each row in this matrix will have 7/3 elements: w1_p ... w4_p ... w7_p. \n",
    "\n",
    "    # Seven Dimensional Support Space (\"Turn on\" as needed/wanted.)\n",
    "        #w_7 = cp.Variable((num_pumas,7),\"wd_p\")\n",
    "\n",
    "    # Three Dimensional Support Space \n",
    "    w_3 = cp.Variable((num_pumas,3),\"wd_p\")\n",
    "    \n",
    "    # Test that the constraint is correctly specified before using it in the max. ent. problem below. \n",
    "    #test_3 = sum( nn_sp_acs[i,0] * (nr_sp_acs[i,0] - (w_3[i,0] * v1_p[i,0]) - (w_3[i,1] * v4_p[i,0]) - ( w_3[i,2] * v7_p[i,0])) for i in range(num_pumas))\n",
    "    #print(test_3)\n",
    "    \n",
    "    # MAXIMUM ENTROPY PROBLEM *******\n",
    "    objective_3 = cp. Maximize(cp.sum(cp.entr(w_3)))\n",
    " \n",
    "    constraints_3 = []\n",
    "    constraints_3 += [ w_3[i,j] >= 0 for i in range(num_pumas) for j in range (3) ] # All elemnts (probabilities) in support space Matrix are greater than zero.  \n",
    "    constraints_3 += [ w_3[i,0] + w_3[i,1] + w_3[i,2] == 1 for i in range(num_pumas) ] # Probabilities spanning each row sum to one. \n",
    "    constraints_3 += [ r_s_cps_num == (sum(((nr_sp_acs[i,0] - (w_3[i,0] * v1_p[i,0]) - (w_3[i,1] * v4_p[i,0]) - (w_3[i,2] * v7_p[i,0])) * nn_sp_acs[i,0])  for i in range(num_pumas)) / n_s_acs_num) ]\n",
    "    constraints_3 += [ (nr_sp_acs[i,0] - (w_3[i,0] * v1_p[i,0]) - (w_3[i,1] * v4_p[i,0]) - ( w_3[i,2] * v7_p[i,0])) >= 0 for i in range(num_pumas) ] #Estimated \"true\" number of poor cannot be negative. \n",
    "    constraints_3 += [ (nr_sp_acs[i,0] - (w_3[i,0] * v1_p[i,0]) - (w_3[i,1] * v4_p[i,0]) - ( w_3[i,2] * v7_p[i,0])) <= 1 for i in range(num_pumas) ] #Estimated \"true\" SPM PUMA rate must be less than one. \n",
    "\n",
    "    prob = cp.Problem(objective_3, constraints_3)\n",
    "    #prob.solve(solver=cp.SCS)\n",
    "    prob.solve(warm_start = True, solver=cp.SCS, verbose=False, max_iters=200000) # Elissa's prob.solve command. \n",
    "\n",
    "    est_w3 = w_3.value\n",
    "    #print(est_w3)\n",
    "    \n",
    "    #Use the results from the estimation to refine ACS PUMA SPM Estimates:\n",
    "    #Grab columns from max. entropy result and save them as matricies \n",
    "    est_w1_p = np.transpose(np.matrix(column(est_w3, 0)))\n",
    "    est_w4_p = np.transpose(np.matrix(column(est_w3, 1)))\n",
    "    est_w7_p = np.transpose(np.matrix(column(est_w3, 2)))\n",
    "\n",
    "    #Multiply each column by respective support element. \n",
    "    w1_v1_p = np.multiply(est_w1_p, v1_p)\n",
    "    w4_v4_p = np.multiply(est_w4_p, v4_p)\n",
    "    w7_v7_p = np.multiply(est_w7_p, v7_p)\n",
    "\n",
    "    #Sum the row element for across each of the three vectors to get approximate error\n",
    "    error = np.add(np.add(w1_v1_p, w4_v4_p), w7_v7_p)\n",
    "    #print(error)\n",
    "\n",
    "    #Subtract error from the original PUMA rates\n",
    "    est_r_sp_acs = np.subtract(nr_sp_acs, error)\n",
    "    \n",
    "    #Check estimates satisfy observed constraint. \n",
    "    numerator = sum(np.multiply(est_r_sp_acs[i,0], nn_sp_acs[i,0]) for i in range(num_pumas)) / n_s_acs_num\n",
    "    #print(numerator) #Resulting state SPM rate from new, estimates PUMA rates \n",
    "    #print(r_s_cps_num) #original state SPM rate from CPS ASEC \n",
    "\n",
    "    if (round(numerator,4) != round(r_s_cps_num,4)):\n",
    "        sys.exit(\"Estimated error does not satisfy observed constraint.\")\n",
    "        \n",
    "    # Make vector into data frame\n",
    "    df = pd.DataFrame(data = est_r_sp_acs, columns = ['max_ent_ests'])\n",
    "    df_ests = df.set_index(np.transpose(index_list)) # Give estimates appropriate index values. \n",
    "\n",
    "    #Append with original data frame\n",
    "    data3 = pd.concat([data2, df_ests], axis=1)\n",
    "\n",
    "    #Export dataset to a new XLSX doc\n",
    "    data3.to_excel(r\"C:\\Users\\Danielle Wilson\\Dropbox\\SPM_ASEC_ACS_project\\Python_exports\\max_ent_ests_gestfips_\" + str(s) + \".xlsx\",  sheet_name= 'Gestfips ' + str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
